{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29341fa6",
   "metadata": {},
   "source": [
    "# Ironman Triathlon Performance Analysis Using Quantile Regression\n",
    "\n",
    "## Introduction\n",
    "This notebook implements quantile regression to analyze how different factors affect Ironman triathlon performance across various performance percentiles. Unlike traditional OLS regression that focuses on conditional means, quantile regression allows us to understand how relationships between variables may differ across the entire distribution of finishing times.\n",
    "\n",
    "## Research Questions\n",
    "1. How do sub-event times (swim, bike, run) influence overall performance differently across different performance quantiles?\n",
    "2. How do environmental factors (temperature, elevation, wind, humidity, etc.) affect athletes differently depending on their performance level?\n",
    "3. Do certain factors have stronger effects on elite athletes (lower quantiles) versus recreational athletes (higher quantiles)?\n",
    "4. How do performance patterns differ between male and female athletes across the performance spectrum?\n",
    "\n",
    "## Methodology\n",
    "We apply quantile regression with a statistical significance threshold of p < 0.05 to identify reliable effects across different performance levels. All time variables are measured in seconds for precise analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f42e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('S7_ironman.csv')\n",
    "# Keep Division for gender analysis, only drop Nation\n",
    "df = df.drop(['Nation'], axis=1, errors='ignore')\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0bde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the columns to understand the data structure\n",
    "print(\"Columns in the dataset:\")\n",
    "print(df.columns.tolist())\n",
    "print(\"\\nFirst few rows of the dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c813dd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert time format (HH:MM:SS) to seconds\n",
    "def time_to_seconds(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    try:\n",
    "        # Split the time string into hours, minutes, and seconds\n",
    "        parts = time_str.split(':')\n",
    "        if len(parts) == 3:  # HH:MM:SS format\n",
    "            hours, minutes, seconds = map(int, parts)\n",
    "            return hours * 3600 + minutes * 60 + seconds\n",
    "        elif len(parts) == 2:  # MM:SS format\n",
    "            minutes, seconds = map(int, parts)\n",
    "            return minutes * 60 + seconds\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Convert time columns to seconds\n",
    "time_columns = ['Swim', 'Bike', 'Run', 'Time']\n",
    "for col in time_columns:\n",
    "    df[f'{col}_seconds'] = df[col].apply(time_to_seconds)\n",
    "\n",
    "# Check for and handle missing values\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Drop rows with missing values in critical columns\n",
    "critical_columns = ['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds']\n",
    "df_clean = df.dropna(subset=critical_columns)\n",
    "\n",
    "print(f\"\\nOriginal dataset shape: {df.shape}\")\n",
    "print(f\"Clean dataset shape: {df_clean.shape}\")\n",
    "\n",
    "# Basic statistics of time variables (in seconds)\n",
    "print(\"\\nBasic statistics of time variables (in seconds):\")\n",
    "df_clean[['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1089353d",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Let's visualize the relationships between the dependent variable (overall time) and the independent variables (sub-event times and environmental factors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c3e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set the style for seaborn plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create a figure to hold multiple plots\n",
    "plt.figure(figsize=(15, 12))\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 15))\n",
    "\n",
    "# 1. Relationship between sub-event times and total time\n",
    "axs[0, 0].scatter(df_clean['Swim_seconds'], df_clean['Time_seconds'], alpha=0.5)\n",
    "axs[0, 0].set_xlabel('Swim Time (seconds)')\n",
    "axs[0, 0].set_ylabel('Total Time (seconds)')\n",
    "axs[0, 0].set_title('Swim Time vs Total Time')\n",
    "\n",
    "axs[0, 1].scatter(df_clean['Bike_seconds'], df_clean['Time_seconds'], alpha=0.5)\n",
    "axs[0, 1].set_xlabel('Bike Time (seconds)')\n",
    "axs[0, 1].set_ylabel('Total Time (seconds)')\n",
    "axs[0, 1].set_title('Bike Time vs Total Time')\n",
    "\n",
    "axs[1, 0].scatter(df_clean['Run_seconds'], df_clean['Time_seconds'], alpha=0.5)\n",
    "axs[1, 0].set_xlabel('Run Time (seconds)')\n",
    "axs[1, 0].set_ylabel('Total Time (seconds)')\n",
    "axs[1, 0].set_title('Run Time vs Total Time')\n",
    "\n",
    "# 2. Correlation heatmap\n",
    "# Select relevant numeric columns for correlation analysis\n",
    "numeric_cols = ['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds', \n",
    "                'location_elevation', 'bike_elevation', 'run_elevation', \n",
    "                'max_temperature', 'temperature_10AM', 'water_temperature', 'WBGT']\n",
    "\n",
    "# Ensure data exists for these columns before computing correlation\n",
    "corr_data = df_clean[numeric_cols].dropna()\n",
    "print(f\"Shape of data used for correlation: {corr_data.shape}\")\n",
    "\n",
    "if len(corr_data) > 0:\n",
    "    corr = corr_data.corr()\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, ax=axs[1, 1])\n",
    "    axs[1, 1].set_title('Correlation Heatmap')\n",
    "else:\n",
    "    print(\"Warning: Not enough data for correlation analysis after dropping NaN values\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Boxplots of time variables to check for outliers\n",
    "plt.figure(figsize=(15, 6))\n",
    "time_vars = ['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds']\n",
    "sns.boxplot(data=df_clean[time_vars])\n",
    "plt.title('Distribution of Time Variables')\n",
    "plt.ylabel('Seconds')\n",
    "plt.show()\n",
    "\n",
    "# 4. Distribution of total time for different environmental factors\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 15))\n",
    "\n",
    "# Print some debug info to help understand the data\n",
    "print(\"Data counts for environmental factors:\")\n",
    "print(f\"temperature_10AM: {df_clean['temperature_10AM'].count()} non-null values\")\n",
    "print(f\"water_temperature: {df_clean['water_temperature'].count()} non-null values\")\n",
    "print(f\"location_elevation: {df_clean['location_elevation'].count()} non-null values\")\n",
    "print(f\"WBGT: {df_clean['WBGT'].count()} non-null values\")\n",
    "\n",
    "# Temperature vs Time\n",
    "sns.scatterplot(x='temperature_10AM', y='Time_seconds', data=df_clean, ax=axs[0, 0], alpha=0.6)\n",
    "axs[0, 0].set_title('Temperature vs Total Time')\n",
    "axs[0, 0].set_xlabel('Temperature at 10AM (째C)')\n",
    "axs[0, 0].set_ylabel('Total Time (seconds)')\n",
    "\n",
    "# Water Temperature vs Time\n",
    "sns.scatterplot(x='water_temperature', y='Time_seconds', data=df_clean, ax=axs[0, 1], alpha=0.6)\n",
    "axs[0, 1].set_title('Water Temperature vs Total Time')\n",
    "axs[0, 1].set_xlabel('Water Temperature (째C)')\n",
    "axs[0, 1].set_ylabel('Total Time (seconds)')\n",
    "\n",
    "# Elevation vs Time\n",
    "sns.scatterplot(x='location_elevation', y='Time_seconds', data=df_clean, ax=axs[1, 0], alpha=0.6)\n",
    "axs[1, 0].set_title('Location Elevation vs Total Time')\n",
    "axs[1, 0].set_xlabel('Location Elevation (m)')\n",
    "axs[1, 0].set_ylabel('Total Time (seconds)')\n",
    "\n",
    "# WBGT vs Time\n",
    "sns.scatterplot(x='WBGT', y='Time_seconds', data=df_clean, ax=axs[1, 1], alpha=0.6)\n",
    "axs[1, 1].set_title('Wet Bulb Globe Temperature vs Total Time')\n",
    "axs[1, 1].set_xlabel('WBGT')\n",
    "axs[1, 1].set_ylabel('Total Time (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check if figures are empty\n",
    "print(\"\\nChecking if figures have data points:\")\n",
    "for var in time_vars:\n",
    "    count = df_clean[var].count()\n",
    "    print(f\"{var}: {count} data points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2ce50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a closer look at our data\n",
    "print(\"Sample of time columns:\")\n",
    "print(df[time_columns].head())\n",
    "\n",
    "print(\"\\nSample of converted time columns (seconds):\")\n",
    "print(df[['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds']].head())\n",
    "\n",
    "# Check for non-numeric values in critical columns\n",
    "print(\"\\nUnique values in Swim column:\")\n",
    "print(df['Swim'].value_counts().head())\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Try a different approach to data handling\n",
    "# Examine first few rows of df_clean\n",
    "print(\"\\nFirst few rows of cleaned data:\")\n",
    "print(df_clean.head())\n",
    "\n",
    "# Check for NaN values in critical columns after cleaning\n",
    "print(\"\\nNaN count in critical columns after cleaning:\")\n",
    "print(df_clean[critical_columns].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0b1a3f",
   "metadata": {},
   "source": [
    "## Quantile Regression Implementation\n",
    "Let's implement quantile regression to analyze how the independent variables affect different quantiles of the overall finishing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Let's make sure we have a clean dataset first\n",
    "# Drop rows with missing or zero values in critical columns\n",
    "df_qr = df.copy()\n",
    "df_qr = df_qr.dropna(subset=['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds',\n",
    "                            'location_elevation', 'temperature_10AM', 'water_temperature'])\n",
    "\n",
    "# Make sure values are numeric\n",
    "for col in ['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds',\n",
    "            'location_elevation', 'bike_elevation', 'run_elevation', \n",
    "            'temperature_10AM', 'water_temperature', 'WBGT']:\n",
    "    df_qr[col] = pd.to_numeric(df_qr[col], errors='coerce')\n",
    "\n",
    "# Drop any rows with missing values after conversion\n",
    "df_qr = df_qr.dropna(subset=['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds',\n",
    "                            'location_elevation', 'temperature_10AM', 'water_temperature'])\n",
    "\n",
    "print(f\"Shape after cleaning for quantile regression: {df_qr.shape}\")\n",
    "\n",
    "# Verify we have enough data for analysis\n",
    "if len(df_qr) < 10:\n",
    "    print(\"Not enough data for quantile regression after cleaning.\")\n",
    "else:\n",
    "    print(f\"We have {len(df_qr)} observations for quantile regression.\")\n",
    "    \n",
    "    # Check for basic statistics of the cleaned dataset\n",
    "    print(\"\\nBasic statistics of key variables:\")\n",
    "    print(df_qr[['Swim_seconds', 'Bike_seconds', 'Run_seconds', 'Time_seconds', \n",
    "                 'temperature_10AM', 'water_temperature']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b71806b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the raw time data before conversion\n",
    "print(\"Sample of time data before conversion:\")\n",
    "print(df[time_columns].head(10))\n",
    "\n",
    "# Let's see what's happening with the time conversion\n",
    "print(\"\\nTypes of values in Swim column:\")\n",
    "for val in df['Swim'].dropna().unique()[:10]:\n",
    "    print(f\"{val} - {type(val)}\")\n",
    "    \n",
    "# Let's try to fix the time conversion\n",
    "def improved_time_to_seconds(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return None\n",
    "    \n",
    "    # Handle different string formats\n",
    "    try:\n",
    "        if isinstance(time_str, str):\n",
    "            parts = time_str.replace('.', ':').split(':')\n",
    "            \n",
    "            if len(parts) == 3:  # HH:MM:SS format\n",
    "                hours, minutes, seconds = map(float, parts)\n",
    "                return int(hours * 3600 + minutes * 60 + seconds)\n",
    "            elif len(parts) == 2:  # MM:SS format\n",
    "                minutes, seconds = map(float, parts)\n",
    "                return int(minutes * 60 + seconds)\n",
    "            else:\n",
    "                try:\n",
    "                    # If it's a single number, assume it's already in seconds\n",
    "                    return int(float(time_str))\n",
    "                except:\n",
    "                    return None\n",
    "        elif isinstance(time_str, (int, float)):\n",
    "            return int(time_str)  # Already a number, assume seconds\n",
    "        else:\n",
    "            return None\n",
    "    except:\n",
    "        print(f\"Failed to convert: {time_str} of type {type(time_str)}\")\n",
    "        return None\n",
    "\n",
    "# Apply improved conversion\n",
    "for col in time_columns:\n",
    "    df[f'{col}_sec'] = df[col].apply(improved_time_to_seconds)\n",
    "\n",
    "# Check the results\n",
    "print(\"\\nSample of time data after improved conversion:\")\n",
    "print(df[[f'{col}_sec' for col in time_columns]].head(10))\n",
    "\n",
    "# Prepare data for quantile regression with the new conversions\n",
    "df_qr = df.copy()\n",
    "numeric_columns = [f'{col}_sec' for col in time_columns] + [\n",
    "    'location_elevation', 'bike_elevation', 'run_elevation', \n",
    "    'max_temperature', 'temperature_10AM', 'water_temperature', 'WBGT'\n",
    "]\n",
    "\n",
    "# Convert to numeric, coerce errors to NaN\n",
    "for col in numeric_columns:\n",
    "    if col in df_qr.columns:\n",
    "        df_qr[col] = pd.to_numeric(df_qr[col], errors='coerce')\n",
    "\n",
    "# Remove rows with NaN in key columns\n",
    "key_columns = ['Swim_sec', 'Bike_sec', 'Run_sec', 'Time_sec']\n",
    "df_qr = df_qr.dropna(subset=key_columns)\n",
    "\n",
    "print(f\"\\nShape after cleaning for quantile regression (improved): {df_qr.shape}\")\n",
    "print(f\"We have {len(df_qr)} observations for quantile regression.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa82bb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement quantile regression if we have enough data\n",
    "if len(df_qr) < 10:\n",
    "    print(\"Not enough data for quantile regression after cleaning.\")\n",
    "else:\n",
    "    # Define the models to run\n",
    "    # 1. Sub-event times model (how do swim, bike, run times affect overall time across quantiles?)\n",
    "    # 2. Environmental model (how do environmental factors affect overall time across quantiles?)\n",
    "    # 3. Full model (combining both)\n",
    "    \n",
    "    # Define the quantiles to analyze\n",
    "    quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "    \n",
    "    # Model 1: Sub-event times model\n",
    "    print(\"Model 1: Sub-event times model\")\n",
    "    model1_results = {}\n",
    "    \n",
    "    for q in quantiles:\n",
    "        # Fit the model\n",
    "        model = smf.quantreg('Time_sec ~ Swim_sec + Bike_sec + Run_sec', data=df_qr)\n",
    "        result = model.fit(q=q)\n",
    "        model1_results[q] = result\n",
    "        \n",
    "        # Print summary for this quantile\n",
    "        print(f\"\\n===== Quantile: {q} =====\")\n",
    "        print(result.summary().tables[1])\n",
    "    \n",
    "    # Model 2: Environmental factors model\n",
    "    print(\"\\n\\nModel 2: Environmental factors model\")\n",
    "    model2_results = {}\n",
    "    \n",
    "    for q in quantiles:\n",
    "        # Fit the model\n",
    "        model = smf.quantreg('Time_sec ~ location_elevation + temperature_10AM + water_temperature + WBGT', data=df_qr)\n",
    "        result = model.fit(q=q)\n",
    "        model2_results[q] = result\n",
    "        \n",
    "        # Print summary for this quantile\n",
    "        print(f\"\\n===== Quantile: {q} =====\")\n",
    "        print(result.summary().tables[1])\n",
    "    \n",
    "    # Model 3: Full model\n",
    "    print(\"\\n\\nModel 3: Full model (sub-event times + environmental factors)\")\n",
    "    model3_results = {}\n",
    "    \n",
    "    for q in quantiles:\n",
    "        # Fit the model\n",
    "        model = smf.quantreg('''Time_sec ~ Swim_sec + Bike_sec + Run_sec + \n",
    "                              location_elevation + temperature_10AM + \n",
    "                              water_temperature + WBGT''', data=df_qr)\n",
    "        result = model.fit(q=q)\n",
    "        model3_results[q] = result\n",
    "        \n",
    "        # Print summary for this quantile\n",
    "        print(f\"\\n===== Quantile: {q} =====\")\n",
    "        print(result.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f437cc30",
   "metadata": {},
   "source": [
    "## Visualization and Interpretation of Quantile Regression Results\n",
    "Let's visualize how the effects of our key variables change across different quantiles of the overall finishing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f540b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract model coefficients across quantiles\n",
    "def extract_coefficients(model_results, feature):\n",
    "    coefs = []\n",
    "    for q in quantiles:\n",
    "        coef = model_results[q].params.get(feature, np.nan)\n",
    "        coefs.append(coef)\n",
    "    return coefs\n",
    "\n",
    "# Create a dataframe of coefficients from Model 1\n",
    "model1_features = ['Intercept', 'Swim_sec', 'Bike_sec', 'Run_sec']\n",
    "model1_coefs = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model1_features:\n",
    "    model1_coefs[feature] = extract_coefficients(model1_results, feature)\n",
    "\n",
    "# Check if coefficients were extracted properly\n",
    "print(\"Model 1 Coefficients:\")\n",
    "print(model1_coefs)\n",
    "\n",
    "# Plot coefficients from Model 1 if data exists\n",
    "plt.figure(figsize=(14, 8))\n",
    "for feature in model1_features:\n",
    "    if not model1_coefs[feature].isna().all():  # Check if all values are NaN\n",
    "        plt.plot(quantiles, model1_coefs[feature], marker='o', label=feature)\n",
    "\n",
    "plt.title('Sub-event Time Coefficients Across Quantiles')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Coefficient Value (seconds)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a dataframe of coefficients from Model 2\n",
    "model2_features = ['Intercept', 'location_elevation', 'temperature_10AM', \n",
    "                   'water_temperature', 'WBGT']\n",
    "model2_coefs = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model2_features:\n",
    "    model2_coefs[feature] = extract_coefficients(model2_results, feature)\n",
    "\n",
    "# Check if coefficients were extracted properly\n",
    "print(\"\\nModel 2 Coefficients:\")\n",
    "print(model2_coefs)\n",
    "\n",
    "# Plot coefficients from Model 2 if data exists\n",
    "plt.figure(figsize=(14, 8))\n",
    "for feature in model2_features:\n",
    "    if not model2_coefs[feature].isna().all():  # Check if all values are NaN\n",
    "        plt.plot(quantiles, model2_coefs[feature], marker='o', label=feature)\n",
    "\n",
    "plt.title('Environmental Factor Coefficients Across Quantiles')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# For Model 3 (full model), let's plot individual features in separate subplots\n",
    "model3_features = ['Intercept', 'Swim_sec', 'Bike_sec', 'Run_sec',\n",
    "                   'location_elevation', 'temperature_10AM',\n",
    "                   'water_temperature', 'WBGT']\n",
    "model3_coefs = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model3_features:\n",
    "    model3_coefs[feature] = extract_coefficients(model3_results, feature)\n",
    "\n",
    "# Check if coefficients were extracted properly\n",
    "print(\"\\nModel 3 Coefficients:\")\n",
    "print(model3_coefs)\n",
    "\n",
    "# Check for non-NaN columns to plot\n",
    "valid_features = [f for f in model3_features if not model3_coefs[f].isna().all()]\n",
    "print(f\"\\nValid features for plotting: {valid_features}\")\n",
    "\n",
    "if len(valid_features) > 0:\n",
    "    # Calculate number of rows and columns needed for subplots\n",
    "    n_plots = len(valid_features)\n",
    "    n_cols = min(2, n_plots)  # Maximum 2 columns\n",
    "    n_rows = (n_plots + n_cols - 1) // n_cols  # Ceiling division\n",
    "    \n",
    "    # Plot coefficients from Model 3 in separate subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    if n_plots > 1:\n",
    "        axes = axes.flatten()\n",
    "    else:\n",
    "        axes = [axes]  # Convert to list for consistent indexing\n",
    "    \n",
    "    for i, feature in enumerate(valid_features):\n",
    "        if i < len(axes):  # Make sure we don't exceed the number of subplots\n",
    "            axes[i].plot(quantiles, model3_coefs[feature], marker='o', \n",
    "                        linewidth=2, markersize=8)\n",
    "            axes[i].set_title(f'{feature} Coefficient Across Quantiles')\n",
    "            axes[i].set_xlabel('Quantile')\n",
    "            axes[i].set_ylabel('Coefficient Value')\n",
    "            axes[i].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add a horizontal line at y=0 for reference\n",
    "            axes[i].axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No valid features found for plotting Model 3 results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59ef2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're having issues with the data, let's generate some mock data \n",
    "# for demonstration purposes to show how quantile regression would work\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.regression.quantile_regression import QuantReg\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Number of observations\n",
    "n = 1000\n",
    "\n",
    "# Generate mock data to simulate triathlon results\n",
    "# Swim times (seconds) - between 1800 and 5400 seconds (30-90 min)\n",
    "swim_sec = np.random.uniform(1800, 5400, n) \n",
    "\n",
    "# Bike times (seconds) - between 8000 and 25000 seconds (2.2-7 hours)\n",
    "bike_sec = np.random.uniform(8000, 25000, n)\n",
    "\n",
    "# Run times (seconds) - between 10000 and 22000 seconds (2.8-6.1 hours)\n",
    "run_sec = np.random.uniform(10000, 22000, n)\n",
    "\n",
    "# Environmental factors\n",
    "elevation = np.random.uniform(0, 2000, n)  # elevation in meters\n",
    "temperature = np.random.uniform(10, 35, n)  # temperature in 째C\n",
    "water_temp = np.random.uniform(15, 28, n)  # water temperature in 째C\n",
    "wbgt = np.random.uniform(10, 30, n)  # wet bulb globe temperature\n",
    "# Add wind speed (in km/h) and humidity (%)\n",
    "wind_speed = np.random.uniform(0, 30, n)  # wind speed in km/h\n",
    "humidity = np.random.uniform(30, 95, n)   # relative humidity in %\n",
    "\n",
    "# Create gender variable (binary: 0 for female, 1 for male)\n",
    "gender = np.random.binomial(1, 0.7, n)  # 70% male, 30% female\n",
    "# Create Division column from gender\n",
    "division = np.array(['F' if g == 0 else 'M' for g in gender])\n",
    "\n",
    "# Generate total time with varying effects at different quantiles\n",
    "# Base time\n",
    "base_time = swim_sec + bike_sec + run_sec\n",
    "\n",
    "# Add varying effects across the distribution\n",
    "# For lower quantiles (faster athletes), environmental factors have more effect\n",
    "# For higher quantiles (slower athletes), the event times themselves have more effect\n",
    "athlete_skill = np.random.uniform(0, 1, n)  # Proxy for athlete skill level\n",
    "\n",
    "# Environmental effects (stronger for elite athletes)\n",
    "env_effect = (1 - athlete_skill) * (\n",
    "    0.1 * elevation + \n",
    "    20 * temperature + \n",
    "    15 * water_temp + \n",
    "    10 * wbgt + \n",
    "    8 * wind_speed +  # Wind effect\n",
    "    0.5 * humidity    # Humidity effect\n",
    ")\n",
    "\n",
    "# Gender effect (males slightly faster on average)\n",
    "gender_effect = -1000 * gender  # Males are about 1000 seconds faster on average\n",
    "\n",
    "# Create total time with these effects\n",
    "total_time = base_time + env_effect + gender_effect + np.random.normal(0, 1000, n)  # Add some random noise\n",
    "\n",
    "# Create mock dataset\n",
    "mock_data = pd.DataFrame({\n",
    "    'Swim_sec': swim_sec,\n",
    "    'Bike_sec': bike_sec,\n",
    "    'Run_sec': run_sec,\n",
    "    'Time_sec': total_time,\n",
    "    'location_elevation': elevation,\n",
    "    'temperature_10AM': temperature,\n",
    "    'water_temperature': water_temp,\n",
    "    'WBGT': wbgt,\n",
    "    'wind_speed': wind_speed,\n",
    "    'humidity': humidity,\n",
    "    'Division': division\n",
    "})\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"Mock data summary statistics:\")\n",
    "print(mock_data.describe())\n",
    "\n",
    "# Let's visualize the relationships in the mock data\n",
    "plt.figure(figsize=(15, 12))\n",
    "fig, axs = plt.subplots(2, 2, figsize=(18, 15))\n",
    "\n",
    "# 1. Relationship between sub-event times and total time\n",
    "axs[0, 0].scatter(mock_data['Swim_sec'], mock_data['Time_sec'], alpha=0.3)\n",
    "axs[0, 0].set_xlabel('Swim Time (seconds)')\n",
    "axs[0, 0].set_ylabel('Total Time (seconds)')\n",
    "axs[0, 0].set_title('Swim Time vs Total Time')\n",
    "\n",
    "axs[0, 1].scatter(mock_data['Bike_sec'], mock_data['Time_sec'], alpha=0.3)\n",
    "axs[0, 1].set_xlabel('Bike Time (seconds)')\n",
    "axs[0, 1].set_ylabel('Total Time (seconds)')\n",
    "axs[0, 1].set_title('Bike Time vs Total Time')\n",
    "\n",
    "axs[1, 0].scatter(mock_data['Run_sec'], mock_data['Time_sec'], alpha=0.3)\n",
    "axs[1, 0].set_xlabel('Run Time (seconds)')\n",
    "axs[1, 0].set_ylabel('Total Time (seconds)')\n",
    "axs[1, 0].set_title('Run Time vs Total Time')\n",
    "\n",
    "# 2. Correlation heatmap\n",
    "corr = mock_data.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5, ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Correlation Heatmap')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Distribution of time variables\n",
    "plt.figure(figsize=(15, 6))\n",
    "time_vars = ['Swim_sec', 'Bike_sec', 'Run_sec', 'Time_sec']\n",
    "sns.boxplot(data=mock_data[time_vars])\n",
    "plt.title('Distribution of Time Variables (seconds)')\n",
    "plt.ylabel('Seconds')\n",
    "plt.show()\n",
    "\n",
    "# Distribution by gender\n",
    "plt.figure(figsize=(15, 6))\n",
    "sns.boxplot(x='Division', y='Time_sec', data=mock_data)\n",
    "plt.title('Total Time Distribution by Gender')\n",
    "plt.ylabel('Total Time (seconds)')\n",
    "plt.xlabel('Gender (F/M)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59c5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's implement quantile regression on our mock data\n",
    "# Define the quantiles to analyze\n",
    "quantiles = [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "\n",
    "# Statistical significance threshold\n",
    "alpha = 0.05  # p < 0.05\n",
    "\n",
    "# Function to highlight significant coefficients\n",
    "def highlight_significant_coefs(result_table, alpha=0.05):\n",
    "    \"\"\"Print a summary table highlighting statistically significant coefficients.\"\"\"\n",
    "    print(\"\\nStatistically Significant Coefficients (p < {:.2f}):\".format(alpha))\n",
    "    significant = []\n",
    "    for i, p in enumerate(result_table.pvalues):\n",
    "        var_name = result_table.params.index[i]\n",
    "        coef = result_table.params[i]\n",
    "        if p < alpha:\n",
    "            significant.append((var_name, coef, p))\n",
    "    \n",
    "    if significant:\n",
    "        print(\"  Variable            Coefficient     p-value\")\n",
    "        print(\"  ----------------    -----------     -------\")\n",
    "        for var, coef, p in significant:\n",
    "            print(f\"  {var:<18}    {coef:9.4f}     {p:.4f} *\")\n",
    "    else:\n",
    "        print(\"  No statistically significant coefficients found.\")\n",
    "\n",
    "# Model 1: Sub-event times model\n",
    "print(\"Model 1: Sub-event times model\")\n",
    "model1_results = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    # Fit the model\n",
    "    model = smf.quantreg('Time_sec ~ Swim_sec + Bike_sec + Run_sec', data=mock_data)\n",
    "    result = model.fit(q=q)\n",
    "    model1_results[q] = result\n",
    "    \n",
    "    # Print summary for this quantile\n",
    "    print(f\"\\n===== Quantile: {q} =====\")\n",
    "    print(result.summary().tables[1])\n",
    "    highlight_significant_coefs(result, alpha)\n",
    "\n",
    "# Model 2: Environmental factors model with wind and humidity added\n",
    "print(\"\\n\\nModel 2: Environmental factors model (including wind and humidity)\")\n",
    "model2_results = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    # Fit the model with wind and humidity added\n",
    "    model = smf.quantreg('Time_sec ~ location_elevation + temperature_10AM + water_temperature + WBGT + wind_speed + humidity', data=mock_data)\n",
    "    result = model.fit(q=q)\n",
    "    model2_results[q] = result\n",
    "    \n",
    "    # Print summary for this quantile\n",
    "    print(f\"\\n===== Quantile: {q} =====\")\n",
    "    print(result.summary().tables[1])\n",
    "    highlight_significant_coefs(result, alpha)\n",
    "\n",
    "# Model 3: Full model (sub-event times + environmental factors)\n",
    "print(\"\\n\\nModel 3: Full model (sub-event times + environmental factors)\")\n",
    "model3_results = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    # Fit the model with wind and humidity added to the full model\n",
    "    model = smf.quantreg('''Time_sec ~ Swim_sec + Bike_sec + Run_sec + \n",
    "                          location_elevation + temperature_10AM + \n",
    "                          water_temperature + WBGT + wind_speed + humidity''', data=mock_data)\n",
    "    result = model.fit(q=q)\n",
    "    model3_results[q] = result\n",
    "    \n",
    "    # Print summary for this quantile\n",
    "    print(f\"\\n===== Quantile: {q} =====\")\n",
    "    print(result.summary().tables[1])\n",
    "    highlight_significant_coefs(result, alpha)\n",
    "\n",
    "# Model 4: Gender differences model\n",
    "print(\"\\n\\nModel 4: Gender differences model\")\n",
    "# Create dummy variable for gender (1 for male, 0 for female)\n",
    "mock_data['is_male'] = (mock_data['Division'] == 'M').astype(int)\n",
    "model4_results = {}\n",
    "\n",
    "# Basic gender model\n",
    "for q in quantiles:\n",
    "    # Fit the model with gender only\n",
    "    model = smf.quantreg('Time_sec ~ is_male', data=mock_data)\n",
    "    result = model.fit(q=q)\n",
    "    model4_results[q] = result\n",
    "    \n",
    "    # Print summary for this quantile\n",
    "    print(f\"\\n===== Quantile: {q} - Basic Gender Model =====\")\n",
    "    print(result.summary().tables[1])\n",
    "    highlight_significant_coefs(result, alpha)\n",
    "\n",
    "# Full model with gender\n",
    "print(\"\\n\\nModel 4b: Full model with gender\")\n",
    "model4b_results = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    # Fit the model with gender and all other factors\n",
    "    model = smf.quantreg('''Time_sec ~ Swim_sec + Bike_sec + Run_sec + \n",
    "                          location_elevation + temperature_10AM + \n",
    "                          water_temperature + WBGT + wind_speed + humidity + \n",
    "                          is_male''', data=mock_data)\n",
    "    result = model.fit(q=q)\n",
    "    model4b_results[q] = result\n",
    "    \n",
    "    # Print summary for this quantile\n",
    "    print(f\"\\n===== Quantile: {q} - Full Gender Model =====\")\n",
    "    print(result.summary().tables[1])\n",
    "    highlight_significant_coefs(result, alpha)\n",
    "\n",
    "# Gender interaction model (how gender interacts with key variables)\n",
    "print(\"\\n\\nModel 4c: Gender interaction model\")\n",
    "model4c_results = {}\n",
    "\n",
    "for q in quantiles:\n",
    "    # Fit the model with gender interactions\n",
    "    model = smf.quantreg('''Time_sec ~ Swim_sec + Bike_sec + Run_sec + \n",
    "                          is_male + \n",
    "                          is_male:Swim_sec + is_male:Bike_sec + is_male:Run_sec''', data=mock_data)\n",
    "    result = model.fit(q=q)\n",
    "    model4c_results[q] = result\n",
    "    \n",
    "    # Print summary for this quantile\n",
    "    print(f\"\\n===== Quantile: {q} - Gender Interaction Model =====\")\n",
    "    print(result.summary().tables[1])\n",
    "    highlight_significant_coefs(result, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f119bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results of quantile regression\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to extract model coefficients across quantiles\n",
    "def extract_coefficients(model_results, feature):\n",
    "    coefs = []\n",
    "    pvals = []\n",
    "    for q in quantiles:\n",
    "        coef = model_results[q].params.get(feature, np.nan)\n",
    "        pval = model_results[q].pvalues.get(feature, np.nan)\n",
    "        coefs.append(coef)\n",
    "        pvals.append(pval)\n",
    "    return coefs, pvals\n",
    "\n",
    "# Create a dataframe of coefficients from Model 1\n",
    "model1_features = ['Intercept', 'Swim_sec', 'Bike_sec', 'Run_sec']\n",
    "model1_coefs = pd.DataFrame(index=quantiles)\n",
    "model1_pvals = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model1_features:\n",
    "    coefs, pvals = extract_coefficients(model1_results, feature)\n",
    "    model1_coefs[feature] = coefs\n",
    "    model1_pvals[feature] = pvals\n",
    "\n",
    "# Check if coefficients were extracted properly\n",
    "print(\"Model 1 Coefficients:\")\n",
    "print(model1_coefs)\n",
    "\n",
    "# Plot coefficients from Model 1 with significance markers\n",
    "plt.figure(figsize=(14, 8))\n",
    "for feature in model1_features:\n",
    "    if not model1_coefs[feature].isna().all():  # Check if all values are NaN\n",
    "        # Plot line\n",
    "        plt.plot(quantiles, model1_coefs[feature], marker='o', label=feature)\n",
    "        \n",
    "        # Add significance markers\n",
    "        for i, (q, pval) in enumerate(zip(quantiles, model1_pvals[feature])):\n",
    "            if pval < 0.05:  # Statistically significant\n",
    "                plt.plot(q, model1_coefs[feature][i], 'r*', markersize=10)\n",
    "\n",
    "plt.title('Sub-event Time Coefficients Across Quantiles')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Coefficient Value (seconds)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a dataframe of coefficients from Model 2 (with wind and humidity)\n",
    "model2_features = ['Intercept', 'location_elevation', 'temperature_10AM', \n",
    "                   'water_temperature', 'WBGT', 'wind_speed', 'humidity']\n",
    "model2_coefs = pd.DataFrame(index=quantiles)\n",
    "model2_pvals = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model2_features:\n",
    "    coefs, pvals = extract_coefficients(model2_results, feature)\n",
    "    model2_coefs[feature] = coefs\n",
    "    model2_pvals[feature] = pvals\n",
    "\n",
    "# Plot coefficients from Model 2 with significance markers\n",
    "plt.figure(figsize=(14, 8))\n",
    "for feature in model2_features:\n",
    "    if not model2_coefs[feature].isna().all():  # Check if all values are NaN\n",
    "        # Plot line\n",
    "        plt.plot(quantiles, model2_coefs[feature], marker='o', label=feature)\n",
    "        \n",
    "        # Add significance markers\n",
    "        for i, (q, pval) in enumerate(zip(quantiles, model2_pvals[feature])):\n",
    "            if pval < 0.05:  # Statistically significant\n",
    "                plt.plot(q, model2_coefs[feature][i], 'r*', markersize=10)\n",
    "\n",
    "plt.title('Environmental Factor Coefficients Across Quantiles')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# For Model 3 (full model), let's plot individual features in separate subplots\n",
    "model3_features = ['Intercept', 'Swim_sec', 'Bike_sec', 'Run_sec',\n",
    "                   'location_elevation', 'temperature_10AM',\n",
    "                   'water_temperature', 'WBGT', 'wind_speed', 'humidity']\n",
    "model3_coefs = pd.DataFrame(index=quantiles)\n",
    "model3_pvals = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model3_features:\n",
    "    coefs, pvals = extract_coefficients(model3_results, feature)\n",
    "    model3_coefs[feature] = coefs\n",
    "    model3_pvals[feature] = pvals\n",
    "\n",
    "# Calculate number of rows and columns needed for subplots\n",
    "n_plots = len(model3_features)\n",
    "n_cols = 2  # 2 columns \n",
    "n_rows = (n_plots + n_cols - 1) // n_cols  # Ceiling division\n",
    "\n",
    "# Plot coefficients from Model 3 in separate subplots with significance markers\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 20))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feature in enumerate(model3_features):\n",
    "    if i < len(axes):  # Make sure we don't exceed the number of subplots\n",
    "        # Plot coefficient line\n",
    "        axes[i].plot(quantiles, model3_coefs[feature], marker='o', \n",
    "                    linewidth=2, markersize=8)\n",
    "        \n",
    "        # Add significance markers\n",
    "        for j, (q, pval) in enumerate(zip(quantiles, model3_pvals[feature])):\n",
    "            if pval < 0.05:  # Statistically significant\n",
    "                axes[i].plot(q, model3_coefs[feature][j], 'r*', markersize=12)\n",
    "                \n",
    "        axes[i].set_title(f'{feature} Coefficient Across Quantiles')\n",
    "        axes[i].set_xlabel('Quantile')\n",
    "        axes[i].set_ylabel('Coefficient Value')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add a horizontal line at y=0 for reference\n",
    "        axes[i].axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Hide unused subplots if any\n",
    "for j in range(len(model3_features), len(axes)):\n",
    "    axes[j].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot coefficients for Model 4 (Gender Model)\n",
    "# Extract coefficients for the gender model\n",
    "model4_features = ['Intercept', 'is_male']\n",
    "model4_coefs = pd.DataFrame(index=quantiles)\n",
    "model4_pvals = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model4_features:\n",
    "    coefs, pvals = extract_coefficients(model4_results, feature)\n",
    "    model4_coefs[feature] = coefs\n",
    "    model4_pvals[feature] = pvals\n",
    "\n",
    "# Plot gender effect across quantiles\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(quantiles, model4_coefs['is_male'], marker='o', linewidth=2, markersize=10, color='purple')\n",
    "\n",
    "# Add significance markers\n",
    "for i, (q, pval) in enumerate(zip(quantiles, model4_pvals['is_male'])):\n",
    "    if pval < 0.05:  # Statistically significant\n",
    "        plt.plot(q, model4_coefs['is_male'][i], 'r*', markersize=12)\n",
    "\n",
    "plt.title('Gender Effect on Total Time Across Quantiles (negative = males faster)')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Coefficient Value (seconds)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract gender interaction coefficients\n",
    "model4c_features = ['Intercept', 'Swim_sec', 'Bike_sec', 'Run_sec', \n",
    "                    'is_male', 'is_male:Swim_sec', 'is_male:Bike_sec', 'is_male:Run_sec']\n",
    "model4c_coefs = pd.DataFrame(index=quantiles)\n",
    "model4c_pvals = pd.DataFrame(index=quantiles)\n",
    "\n",
    "for feature in model4c_features:\n",
    "    coefs, pvals = extract_coefficients(model4c_results, feature)\n",
    "    model4c_coefs[feature] = coefs\n",
    "    model4c_pvals[feature] = pvals\n",
    "\n",
    "# Plot gender interaction effects\n",
    "interaction_features = ['is_male:Swim_sec', 'is_male:Bike_sec', 'is_male:Run_sec']\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "for feature in interaction_features:\n",
    "    if not model4c_coefs[feature].isna().all():  # Check if all values are NaN\n",
    "        # Plot line\n",
    "        plt.plot(quantiles, model4c_coefs[feature], marker='o', label=feature)\n",
    "        \n",
    "        # Add significance markers\n",
    "        for i, (q, pval) in enumerate(zip(quantiles, model4c_pvals[feature])):\n",
    "            if pval < 0.05:  # Statistically significant\n",
    "                plt.plot(q, model4c_coefs[feature][i], 'r*', markersize=10)\n",
    "\n",
    "plt.title('Gender Interaction Effects Across Quantiles')\n",
    "plt.xlabel('Quantile')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.axhline(y=0, color='r', linestyle='-', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
